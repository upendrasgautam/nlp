{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f61dee8d",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "Stemming is the process of reducing words to their root form, which helps in text normalization for tasks like search and text analysis. \n",
    "\n",
    "| Original words: ['running', 'jumps', 'happily', 'running', 'happily']|\n",
    "|----------------------------------------------------------------------|\n",
    "| Stemmed words: ['run', 'jump', 'happili', 'run', 'happili']          |\n",
    "\n",
    "### Types of Stemmer in NLTK\n",
    "1) Porter's Stemmer\n",
    "2) Regexp Stemmer\n",
    "3) Snowball Stemmer (Best technique)\n",
    "4) etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0ea6fb",
   "metadata": {},
   "source": [
    "### ## 1. Porter's Stemmer\n",
    "The group of stems is mapped on to the same stem and the output stem is not necessarily a meaningful word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733530e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['running', 'jumps', 'happily', 'running', 'happily']\n",
      "Stemmed words: ['run', 'jump', 'happili', 'run', 'happili']\n"
     ]
    }
   ],
   "source": [
    "## 1. Porter's Stemmer\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Create a Porter Stemmer instance\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Example words for stemming\n",
    "words = [\"running\", \"jumps\", \"happily\", \"running\", \"happily\"]\n",
    "\n",
    "# Apply stemming to each word\n",
    "stemmed_words = [porter_stemmer.stem(word) for word in words]\n",
    "\n",
    "# Print the results\n",
    "print(\"Original words:\", words)\n",
    "print(\"Stemmed words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b9fbc4",
   "metadata": {},
   "source": [
    "### ## 2. Regexp Stemmer\n",
    "The Regexp Stemmer, or Regular Expression Stemmer, is a stemming algorithm that utilizes regular expressions to identify and remove suffixes from words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1393492d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Word: running\n",
      "Stemmed Word: runn\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "# Create a Regexp Stemmer with a custom rule\n",
    "# $ - If youhave not used the $ sign in the last regular expression then it will remove all the ing from the word\n",
    "custom_rule = r'ing$'\n",
    "regexp_stemmer = RegexpStemmer(custom_rule)\n",
    "\n",
    "# Apply the stemmer to a word\n",
    "word = 'running'\n",
    "stemmed_word = regexp_stemmer.stem(word)\n",
    "\n",
    "print(f'Original Word: {word}')\n",
    "print(f'Stemmed Word: {stemmed_word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ad182",
   "metadata": {},
   "source": [
    "### ## 3. Snowball Stemmer\n",
    "The Snowball Stemmer, compared to the Porter Stemmer, is multi-lingual as it can handle non-English words. It supports various languages and is based on the 'Snowball' programming language, known for efficient processing of small strings.\n",
    "\n",
    "The Snowball stemmer is way more aggressive than Porter Stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3a2aacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['running', 'jumped', 'happily', 'quickly', 'foxes']\n",
      "Stemmed words: ['run', 'jump', 'happili', 'quick', 'fox']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Choose a language for stemming, for example, English\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "# Example words to stem\n",
    "words_to_stem = ['running', 'jumped', 'happily', 'quickly', 'foxes']\n",
    "\n",
    "# Apply Snowball Stemmer\n",
    "stemmed_words = [stemmer.stem(word) for word in words_to_stem]\n",
    "\n",
    "# Print the results\n",
    "print(\"Original words:\", words_to_stem)\n",
    "print(\"Stemmed words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd39f93",
   "metadata": {},
   "source": [
    "### Disadvantage of Stemming\n",
    "Loss of meaning of some words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bcb0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
